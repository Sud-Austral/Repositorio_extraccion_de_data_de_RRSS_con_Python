{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping sobre los post de p√°ginas de Facebook\n",
    "\n",
    "Fuente:\n",
    "\n",
    "https://minimaxir.com/2015/07/facebook-scraper/\n",
    "\n",
    "https://github.com/minimaxir/facebook-page-post-scraper/blob/master/examples/how_to_build_facebook_scraper.ipynb\n",
    "\n",
    "How to Download a Facebook Page Posts and Comments to Excel with Python:\n",
    "\n",
    "https://onlinezhuanjia.com/python-facebook-page-scraper-tool/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acceso a los datos de la p√°gina de Facebook requiere un token de acceso.\n",
    "Dado que el token de acceso de usuario caduca dentro de una hora, necesitamos crear una aplicaci√≥n ficticia con el √∫nico prop√≥sito de raspar y usar el ID de la aplicaci√≥n y el secreto de la aplicaci√≥n generados all√≠ como se describe aqu√≠, los cuales nunca caducan.\n",
    "\n",
    "https://developers.facebook.com/docs/facebook-login/access-tokens#apptokens\n",
    "\n",
    "IDENTIFICADOR DE LA APP: 615060279226779\n",
    "\n",
    "Token de cliente:        e2828d07bab87d46d5edcf8df49e798c\n",
    "\n",
    "API facebook: https://facebook-sdk.readthedocs.io/en/latest/api.html#class-facebook-graphapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping BarackObama Facebook Page: 2020-03-15 13:24:29.446083\n",
      "\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.9/BarackObama/posts/?limit=100&amp;amp;amp;amp;access_token=615060279226779|Fi9fxsS8onNd73aOIFg1r47CfTs&amp;amp;amp;amp;since=2018-01-01&amp;amp;amp;amp;until=2018-01-30&amp;amp;amp;amp;fields=message,link,permalink_url,created_time,type,name,id,comments.limit(0).summary(true),shares,reactions.limit(0).summary(true): 2020-03-15 13:24:34.733466\n",
      "Retrying.\n",
      "HTTP Error 400: Bad Request\n",
      "Error for URL https://graph.facebook.com/v2.9/BarackObama/posts/?limit=100&amp;amp;amp;amp;access_token=615060279226779|Fi9fxsS8onNd73aOIFg1r47CfTs&amp;amp;amp;amp;since=2018-01-01&amp;amp;amp;amp;until=2018-01-30&amp;amp;amp;amp;fields=message,link,permalink_url,created_time,type,name,id,comments.limit(0).summary(true),shares,reactions.limit(0).summary(true): 2020-03-15 13:24:39.944863\n",
      "Retrying.\n",
      "HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f4ce320ac4e5>\u001b[0m in \u001b[0;36mrequest_until_succeed\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f4ce320ac4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0mscrapeFacebookPageFeedStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msince_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-f4ce320ac4e5>\u001b[0m in \u001b[0;36mscrapeFacebookPageFeedStatus\u001b[1;34m(page_id, access_token, since_date, until_date)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFacebookPageFeedUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             \u001b[0mstatuses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_until_succeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mreactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetReactionsForStatuses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-f4ce320ac4e5>\u001b[0m in \u001b[0;36mrequest_until_succeed\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error for URL {}: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "try:\n",
    "    from urllib.request import urlopen, Request\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen, Request\n",
    " \n",
    "# app_id = \"615060279226779\"\n",
    "# app_secret = \"a3b9cd27faf240ff46b6509c15089a77\"\n",
    "page_id = \"BarackObama\"\n",
    " \n",
    "# input date formatted as YYYY-MM-DD\n",
    "since_date = \"2018-01-01\"\n",
    "until_date = \"2018-01-30\"\n",
    " \n",
    "# access_token = app_id + \"|\" + app_secret\n",
    "access_token = \"615060279226779|Fi9fxsS8onNd73aOIFg1r47CfTs\"\n",
    " \n",
    " \n",
    "def request_until_succeed(url):\n",
    "    req = Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try:\n",
    "            response = urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    " \n",
    "            print(\"Error for URL {}: {}\".format(url, datetime.datetime.now()))\n",
    "            print(\"Retrying.\")\n",
    " \n",
    "    return response.read()\n",
    " \n",
    " \n",
    "# Needed to write tricky unicode correctly to csv\n",
    "def unicode_decode(text):\n",
    "    try:\n",
    "        return text.encode('utf-8').decode()\n",
    "    except UnicodeDecodeError:\n",
    "        return text.encode('utf-8')\n",
    " \n",
    " \n",
    "def getFacebookPageFeedUrl(base_url):\n",
    " \n",
    "    # Construct the URL string; see http://stackoverflow.com/a/37239851 for\n",
    "    # Reactions parameters\n",
    "    fields = \"&amp;amp;amp;amp;fields=message,link,permalink_url,created_time,type,name,id,\" + \\\n",
    "        \"comments.limit(0).summary(true),shares,reactions\" + \\\n",
    "        \".limit(0).summary(true)\"\n",
    " \n",
    "    return base_url + fields\n",
    " \n",
    " \n",
    "def getReactionsForStatuses(base_url):\n",
    " \n",
    "    reaction_types = ['like', 'love', 'wow', 'haha', 'sad', 'angry']\n",
    "    reactions_dict = {}   # dict of {status_id: tuple&amp;amp;amp;lt;6&amp;amp;amp;gt;}\n",
    " \n",
    "    for reaction_type in reaction_types:\n",
    "        fields = \"&amp;amp;amp;amp;fields=reactions.type({}).limit(0).summary(total_count)\".format(\n",
    "            reaction_type.upper())\n",
    " \n",
    "        url = base_url + fields\n",
    " \n",
    "        data = json.loads(request_until_succeed(url))['data']\n",
    " \n",
    "        data_processed = set()  # set() removes rare duplicates in statuses\n",
    "        for status in data:\n",
    "            id = status['id']\n",
    "            count = status['reactions']['summary']['total_count']\n",
    "            data_processed.add((id, count))\n",
    " \n",
    "        for id, count in data_processed:\n",
    "            if id in reactions_dict:\n",
    "                reactions_dict[id] = reactions_dict[id] + (count,)\n",
    "            else:\n",
    "                reactions_dict[id] = (count,)\n",
    " \n",
    "    return reactions_dict\n",
    " \n",
    " \n",
    "def processFacebookPageFeedStatus(status):\n",
    " \n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    " \n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    " \n",
    "    status_id = status['id']\n",
    "    status_type = status['type']\n",
    " \n",
    "    status_message = '' if 'message' not in status else \\\n",
    "        unicode_decode(status['message'])\n",
    "    link_name = '' if 'name' not in status else \\\n",
    "        unicode_decode(status['name'])\n",
    "    status_link = '' if 'link' not in status else \\\n",
    "        unicode_decode(status['link'])\n",
    "    status_permalink_url = '' if 'permalink_url' not in status.keys() else \\\n",
    "            unicode_decode(status['permalink_url'])\n",
    " \n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    " \n",
    "    status_published = datetime.datetime.strptime(\n",
    "        status['created_time'], '%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + \\\n",
    "        datetime.timedelta(hours=-5)  # EST\n",
    "    status_published = status_published.strftime(\n",
    "        '%Y-%m-%d %H:%M:%S')  # best time format for spreadsheet programs\n",
    " \n",
    "    # Nested items require chaining dictionary keys.\n",
    " \n",
    "    num_reactions = 0 if 'reactions' not in status else \\\n",
    "        status['reactions']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status else \\\n",
    "        status['comments']['summary']['total_count']\n",
    "    num_shares = 0 if 'shares' not in status else status['shares']['count']\n",
    " \n",
    "    return (status_id, status_message, link_name, status_type, status_link,status_permalink_url,\n",
    "            status_published, num_reactions, num_comments, num_shares)\n",
    " \n",
    " \n",
    "def scrapeFacebookPageFeedStatus(page_id, access_token, since_date, until_date):\n",
    "    with open('{}_facebook_statuses.csv'.format(page_id), 'w',encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\",\"permalink_url\", \"status_published\", \"num_reactions\",\n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\",\n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\",\n",
    "                    \"num_special\"])\n",
    " \n",
    "        has_next_page = True\n",
    "        num_processed = 0\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "        after = ''\n",
    "        base = \"https://graph.facebook.com/v2.9\"\n",
    "        node = \"/{}/posts\".format(page_id)\n",
    "        parameters = \"/?limit={}&amp;amp;amp;amp;access_token={}\".format(100, access_token)\n",
    "        since = \"&amp;amp;amp;amp;since={}\".format(since_date) if since_date \\\n",
    "            is not '' else ''\n",
    "        until = \"&amp;amp;amp;amp;until={}\".format(until_date) if until_date \\\n",
    "            is not '' else ''\n",
    " \n",
    "        print(\"Scraping {} Facebook Page: {}\\n\".format(page_id, scrape_starttime))\n",
    " \n",
    "        while has_next_page:\n",
    "            after = '' if after is '' else \"&amp;amp;amp;amp;after={}\".format(after)\n",
    "            base_url = base + node + parameters + after + since + until\n",
    " \n",
    "            url = getFacebookPageFeedUrl(base_url)\n",
    "            statuses = json.loads(request_until_succeed(url))\n",
    "            reactions = getReactionsForStatuses(base_url)\n",
    " \n",
    "            for status in statuses['data']:\n",
    " \n",
    "                # Ensure it is a status with the expected metadata\n",
    "                if 'reactions' in status:\n",
    "                    status_data = processFacebookPageFeedStatus(status)\n",
    "                    reactions_data = reactions[status_data[0]]\n",
    " \n",
    "                    # calculate thankful/pride through algebra\n",
    "                    num_special = status_data[7] - sum(reactions_data)\n",
    "                    w.writerow(status_data + reactions_data + (num_special,))\n",
    " \n",
    "                num_processed += 1\n",
    "                if num_processed % 100 == 0:\n",
    "                    print(\"{} Statuses Processed: {}\".format\n",
    "                          (num_processed, datetime.datetime.now()))\n",
    " \n",
    "            # if there is no next page, we're done.\n",
    "            if 'paging' in statuses:\n",
    "                after = statuses['paging']['cursors']['after']\n",
    "            else:\n",
    "                has_next_page = False\n",
    " \n",
    "        print(\"\\nDone!\\n{} Statuses Processed in {}\".format(\n",
    "              num_processed, datetime.datetime.now() - scrape_starttime))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    scrapeFacebookPageFeedStatus(page_id, access_token, since_date, until_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-af61fb1d6d18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbase_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://mobile.facebook.com'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    base_url = 'https://mobile.facebook.com'\n",
    "    session = requests.session()\n",
    " \n",
    "    # Extracts credentials for the login and all of the profiles URL to scrape\n",
    "    credentials = json_to_obj('credentials.json')\n",
    "    profiles_urls = json_to_obj('profiles_urls.json')\n",
    " \n",
    "    make_login(session, base_url, credentials)\n",
    " \n",
    "    posts_data = None\n",
    "    for profile_url in profiles_urls:\n",
    "        posts_data = crawl_profile(session, base_url, profile_url, 25)\n",
    "    logging.info('[!] Scraping finished. Total: {}'.format(len(posts_data)))\n",
    "    logging.info('[!] Saving.')\n",
    "    save_data(posts_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Jeopardy! clue:\n",
      "These trailblazers will boldly go where no woman or man has gone before during future #Artemis missions to space\n",
      "Response:\n",
      "Who are NASA Astronauts? üë®üèª‚ÄçüöÄüë©üèø‚ÄçüöÄ\n",
      "Want to explore the Moon & Mars and make history? Apply today to #BeAnAstronaut: https://go.nasa.gov/2U3zs2P\n",
      "What‚Äôs one perk about applying to #BeAnAstronaut? You‚Äôre one step closer to being on top of the world, because going on spacewalks is part of the job: https://go.nasa.gov/2ILsSsE\n",
      "How to apply: https://go.nasa.gov/39VoCCP\n",
      "NASA's Johnson Space Center\n",
      "March 13 at 1:00 PM ¬∑\n",
      "An inflatable habitat. Winglets on a commercial airplane. A solar refrigerator. Kris Romig shares how NASA tech starts at NASA and makes its way into the world as part of our daily lives on this week‚Äôs ‚ÄúHouston We Have a Podcast.‚Äù üåé https://www.nasa.gov/johnson/HWHAP/nasa-tech-in-the-world\n",
      "NASA's Hubble Space Telescope is looking for the aftermath of a really big meal ‚Äî a star swallowed up by the black hole at the center of a galaxy. Take a look yourself: https://go.nasa.gov/33dXQmC\n",
      "Rocket science - it's as easy as Pi! üöÄü•ß\n",
      "This #PiDay take a look at some of the ways we use this irreplaceable irrational number to solve problems and explore space: https://go.nasa.gov/33gm5kf\n",
      "NASA's Glenn Research Center added 10 new photos to the album: Orion Completes Testing at Plum Brook Station.\n",
      "Yesterday at 12:32 PM ¬∑\n",
      "On Saturday, March 14, NASA Glenn celebrated the completion of testing the Orion spacecraft at NASA‚Äôs Plum Brook Station in Sandusky, Ohio. The event was attended by NASA Glenn Director Dr. Marla P√©rez-Davis and Orion Program Manager Mark Kirasich. U.S. Rep. Marcy Kaptur joined the event to view the spacecraft and provide congratulatory remarks to the team that co\n",
      "Everyone wants a piece of this cosmic pi üíÅ‚Äç‚ôÄÔ∏è\n",
      "This #PiDay, learn more about pi and how it helps us explore the universe! https://go.nasa.gov/2QfImtg\n",
      "This week, we honored the past by remembering Katherine Johnson, kept at work in the present with new science aboard the International Space Station, and looked to the future when we selected the first instruments for Gateway, our outpost in lunar orbit. These are a few of the stories to tell you about ‚Äì This Week at NASA! Watch:\n",
      "Five years ago, we launched a quartet of satellites to study an explosive phenomenon at the heart of space weather storms around Earth. Here's what we've learned from their journey so far: https://go.nasa.gov/2wQLFAe\n",
      "Are you NASA's Hubble Space Telescope? Because you seem...reflective. üòè\n",
      "5,500 galaxies are seen in this photo that combines 10 years of Hubble images. The patch of sky photographed is just a fraction of the width of a full Moon as seen from Earth. For more spectacular images of the universe, check out our Hubble image gallery:: https://go.nasa.gov/3aQmpbZ\n",
      "This week on #SpacetoGround, a SpaceX cargo craft arrived at the International Space Station carrying more than two tons of supplies, including new experiments for studying stem cells and assessing technologies in the harsh environment of space:\n",
      "Since 2015, our record-breaking Magnetospheric Multiscale Mission has been studying the mysterious process that drives giant explosions in space and expanding our understanding of these charged near-Earth events. Discover how: https://go.nasa.gov/3aRtNUi\n",
      "Seize the day. Apply to #BeAnAstronaut.\n",
      "As an #Artemis explorer, you will have the chance to learn invaluable skills and use them to journey to the Moon, Mars and beyond. Don‚Äôt wait to apply: https://go.nasa.gov/3cRVVIR\n",
      "There's nothing like a big slice of 3.14159 ü•ß\n",
      "#PiDay is coming up! Looking for activities for future scientists and engineers? Participate in these mathematical challenges that mimic the ones we face in real NASA missions: https://go.nasa.gov/2IGeCkV\n",
      "Today marks the 108th birthday of Girl Scouts in the United States! #BecauseofGirlScouts, generations of girls have been inspired to become leaders in STEM fields ‚Äî many of whom have gone on to become NASA Astronauts! üë©üèø‚ÄçüöÄüë©üèª‚ÄçüöÄüë©üèΩ‚ÄçüöÄ https://go.nasa.gov/38NcJNM\n",
      "Flying science to the Moon!\n",
      "We‚Äôve selected the first two science payloads to fly on Gateway, our #Artemis orbital outpost. Studying radiation and space weather, these instruments will help astronauts on and around the Moon as well as on future missions to Mars. Learn more: https://go.nasa.gov/3cVpUiX\n",
      "Assembly of the next X-plane for NASA Aeronautics is underway at Lockheed Martin, using a time-honored tradition in aerospace: repurposing components. ‚úàÔ∏è When pushing technology in shape and configuration, integrating reliable aircraft parts helps to save time and money: https://go.nasa.gov/3aNHJi5\n",
      "üåñ Scouting terrain\n",
      "üîç Prospecting for resources\n",
      "üì° Communications and navigation\n",
      "University teams are helping to develop technologies for small satellites that could lead the way for #Artemis missions to the Moon: https://go.nasa.gov/3cTaQ5q\n",
      "Astronauts serve as the eyes and hands of researchers aboard the International Space Station. Get a peek into the world of astronaut science training that you could experience if you get selected to #BeAnAstronaut from the next round of applications!\n",
      "Look like something you would like to do? Get more info on how you can apply to be an astronaut here: http://go.nasa.gov/2VJjttv\n",
      "NASA Explorers is with NASA Astronauts and 2 others.\n",
      "February 12 at 4:00 PM ¬∑\n",
      "It‚Äôs time to go to class with an astronaut\n",
      "Meteorological spring has sprung in the Northern Hemisphere, waking up lively swirls of phytoplankton in the North Atlantic Ocean. Like plants on land, the primary producers of the sea need sunlight and nutrients to thrive. Springtime brings both:\n",
      "https://go.nasa.gov/2Q70zcg\n",
      "On this season's final episode of our #NASAExplorers series: what we've learned! Two scientists who've seen their experiments launched and their research performed on the International Space Station explain what microgravity has to teach us. Although the thrill of the launch may be over, they still have one of the most exciting parts of their journey ahead: sharing their results with the world. Watch:\n",
      "Fifty years ago this week, Apollo 13 crew members Jim Lovell, Ken Mattingly and Fred Haise were training at NASA's Johnson Space Center for a mission that would put everybody's skills to the test. One month till launch: https://go.nasa.gov/2W3GabR\n",
      "#Apollo50th\n",
      "What is #astrobiology? The study of the origin, evolution and distribution of life in the universe. Follow NASA Astrobiology for the latest on what we've learned and how our missions are searching for it:\n",
      "NASA Astrobiology\n",
      "March 11 at 10:55 AM ¬∑\n",
      "The search for and understanding of life beyond Earth has fascinated humans since the beginning of time. Are we alone, or can life exist elsewhere in the universe? We‚Äôre excited to take you on our #astrobiology journey as we seek to answer this question \n",
      "‚ÄúWhen you look out into the depths of space you realize just the vast ocean of darkness, and we‚Äôre on this little island. And we‚Äôre on it together.‚Äù\n",
      "NASA Astronaut Nick Hague shares how his time living and working in space changed his perception of life back on Earth: https://youtu.be/6DR2_VnyinM\n",
      "What do slime mold and the universe have in common? ü§î\n",
      "A lot, actually. Slime mold builds complex networks in search of food, not unlike how gravity builds a cobweb structure of galaxies. https://go.nasa.gov/2TDp5UA\n",
      "#DidYouKnow there's a cosmic ray detector on the International Space Station, studying fundamental particles from sources up to billions of light years away? How the Alpha Magnetic Spectrometer searches for evidence of dark matter:\n",
      "NASA Jet Propulsion Laboratory\n",
      "March 10 at 1:49 PM ¬∑\n",
      "Hungry for some pi? ü•ß\n",
      "Take part in the #NASAPiDayChallenge to get a taste of some of the math NASA engineers and scientists do to explore the universe. Check back with us and NASA Jet Propulsion Laboratory - Education on March 16 to compare your #PiDay answers: go.nasa.gov/2mIHbUu\n",
      "This summer, after a year of studying the near-Earth asteroid Bennu, NASA's OSIRIS-REx Asteroid Sample Return Mission spacecraft will undertake its first-ever attempt to touch the surface of the rocky world, collect a sample of it and safely back away. Here's how: https://go.nasa.gov/2xsmJiH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space is waiting for you!\n",
      "You have 3 weeks left to get your applications in to join the newest class of explorers.\n",
      "Don‚Äôt miss your chance to #BeAnAstronaut: https://go.nasa.gov/2v9tntk\n",
      "Tonight's full Moon is a supermoon! It's also known as the:\n",
      "üåï Crow Moon\n",
      "üåï Crust Moon\n",
      "üåï Sap Moon\n",
      "üåï Sugar Moon\n",
      "üåï Worm Moon\n",
      "No matter what you call it, be sure to go outside and observe: https://go.nasa.gov/3cNVpMa\n",
      "It‚Äôs #NationalMeatballDay ‚Äî did you know our insignia is nicknamed ‚Äúthe meatball‚Äù?\n",
      "üîµ The round shape represents a planet.\n",
      "‚ú® The stars represent space.\n",
      "‚úàÔ∏è The red v-shaped wing represents aeronautics.\n",
      "üí´ The circular orbit represents space travel.\n",
      "Learn more: https://go.nasa.gov/38DYFWO\n",
      "There's no #Artemis without art! üé∂ üé≠ üé® The Greek myth of Artemis, twin sister of Apollo, inspired the name of our program to return astronauts to the Moon. The story also fascinated musician Lindsey Stirling, who visited NASA's Kennedy Space Center to perform her song, 'Artemis,' at Launch Control. Watch: https://youtu.be/h0oclM1Yw2A\n",
      "Veggies in space üå±üõ∞Ô∏è!\n",
      "Understanding the influence of gravity on plants is essential for long-duration missions to the Moon and Mars. It also has global impacts for harvesting on Earth. Learn about the International Space Station study: https://go.nasa.gov/2TO8KeF\n",
      "The formation of planets and stars, the strange behavior of magnetic fields and the chemistry of galaxies: our SOFIA Stratospheric Observatory for Infrared Astronomy sees them all with its infrared eye. In this image, brightly glowing regions reveal where & how massive new stars are born: https://go.nasa.gov/2TyHQs9\n",
      "LIVE NOW: Hear scientists from around the world discuss a pioneering trio of instruments aimed at improving our understanding of air quality. Have NASA Earth questions? Use #AskNASA: https://www.nasa.gov/live\n",
      "The SpaceX Dragon is soon to arrive at the International Space Station with a delivery of over 4,300 pounds of research and supplies. Watch NASA TV as astronaut Jessica Meir uses the station's robotic arm to grapple the spacecraft: https://www.nasa.gov/live\n",
      "üï† 5:30 a.m. EDT: Rendezvous and capture\n",
      "üï£ 8:30 a.m.: Installation\n",
      "On Feb. 28, NASA Earth satellites observed reduced levels of atmospheric nitrogen dioxide over China since the coronavirus outbreak. But measurable change in one pollutant does not mean air quality is suddenly healthy. Here's why: https://go.nasa.gov/2wBhVqW\n",
      "NASA's Johnson Space Center\n",
      "March 8 at 2:00 PM ¬∑\n",
      "Happy #InternationalWomensDay! As of March 2020, 65 women have flown in space. Of these, 38 have worked aboard the International Space Station as long-duration crew members. Women have contributed to construction of station, served as shuttle pilots and commanders, commanded station expeditions and participated in numerous spacewalks including the recent series of all-woman excursions. Women currently hold the record for the single longest spacefl\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/facebook-scraper/\n",
    "# Se pueden extraer los post de cualquier p√°gina de \n",
    "# Facebook sin necesidad de autenticaci√≥n alguna.\n",
    "from facebook_scraper import get_posts\n",
    "for post in get_posts('NASA', pages=10):\n",
    "    print(post['text'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '121447789451413', 'name': 'Christian Castro'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import facebook\n",
    "graph = facebook.GraphAPI(access_token = 'EAADUCx9H1b4BAKgLQlodIERBVdOshlEJDdyKJ58SrievGHa6ZAZCUq0ZAg1jzJdmJiJElGYyqANim6nhKh2iwvYZBfdi2MXJXeo6Bd098j0X5bsMnVb9DK09XhPvobv5d30KrjBkaf2u4PAQI2GBAbZAIaLBKO2z3mz0krHNXuAZDZD', version=\"2.12\")\n",
    "graph.get_object(id = 'me', fields = 'id, name')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobolic is a web consultancy located in Washington DC.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve information about a website or page:\n",
    "site_info = graph.get_object(id=\"https%3A//mobolic.com\",fields=\"og_object\")\n",
    "print(site_info[\"og_object\"][\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://elfsight.com/blog/2017/10/how-to-get-facebook-access-token/\n",
    "Mi token:    \n",
    "EAADUCx9H1b4BAKgLQlodIERBVdOshlEJDdyKJ58SrievGHa6ZAZCUq0ZAg1jzJdmJiJElGYyqANim6nhKh2iwvYZBfdi2MXJXeo6Bd098j0X5bsMnVb9DK09XhPvobv5d30KrjBkaf2u4PAQI2GBAbZAIaLBKO2z3mz0krHNXuAZDZD\n",
    "233144234530238\n",
    "\n",
    "https://facebook-sdk.readthedocs.io/en/latest/api.html\n",
    "    \n",
    "    Token de la NASA:\n",
    "        233144234530238|7Ubaqd1zZDWOwj7K1Ag1Illdbcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "GraphAPIError",
     "evalue": "(#200) If posting to a group, requires app being installed in the group, and \\\n          either publish_to_groups permission with user token, or both manage_pages \\\n          and publish_pages permission with page token; If posting to a page, \\\n          requires both manage_pages and publish_pages as an admin with \\\n          sufficient administrative permission",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGraphAPIError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7bfad86132c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Write 'Hello, world' to the active user's wall.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m graph.put_object(parent_object='me', connection_name='feed',\n\u001b[1;32m----> 3\u001b[1;33m                  message='Hello, world')\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Add a link and write a message about it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\facebook\\__init__.py\u001b[0m in \u001b[0;36mput_object\u001b[1;34m(self, parent_object, connection_name, **data)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;34m\"{0}/{1}/{2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mpost_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         )\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\facebook\\__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, path, args, post_args, files, method)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mGraphAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGraphAPIError\u001b[0m: (#200) If posting to a group, requires app being installed in the group, and \\\n          either publish_to_groups permission with user token, or both manage_pages \\\n          and publish_pages permission with page token; If posting to a page, \\\n          requires both manage_pages and publish_pages as an admin with \\\n          sufficient administrative permission"
     ]
    }
   ],
   "source": [
    " # Write 'Hello, world' to the active user's wall.\n",
    " graph.put_object(parent_object='me', connection_name='feed',\n",
    "                  message='Hello, world')\n",
    "\n",
    "# Add a link and write a message about it.\n",
    "graph.put_object(\n",
    "   parent_object=\"me\",\n",
    "   connection_name=\"feed\",\n",
    "   message=\"This is a great website. Everyone should visit it.\",\n",
    "   link=\"https://www.facebook.com\")\n",
    "\n",
    " # Write a comment on a post.\n",
    " graph.put_object(parent_object='post_id', connection_name='comments',\n",
    "                  message='First!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: use options instead of firefox_options\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'geckodriver' executable needs to be in PATH. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \"'%s' executable may have wrong permissions. %s\" % (\n\u001b[1;32m---> 76\u001b[1;33m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[0;32m     77\u001b[0m                 )\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-13569f684d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFirefoxOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_preference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dom.push.enabled\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirefox_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\firefox\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, firefox_profile, firefox_binary, timeout, capabilities, proxy, executable_path, options, service_log_path, firefox_options, service_args, desired_capabilities, log_path, keep_alive)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m             raise WebDriverException(\n\u001b[0;32m     82\u001b[0m                 \u001b[1;34m\"The executable %s needs to be available in the path. %s\\n%s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 (os.path.basename(self.path), self.start_error_message, str(e)))\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'geckodriver' executable needs to be in PATH. \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "\n",
    "#driver = webdriver.Firefox()\n",
    "# ÈÄöÁü•„ÅÆÁÑ°ÂäπÂåñ\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.set_preference(\"dom.push.enabled\", False)\n",
    "driver = webdriver.Firefox(firefox_options=options)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.facebook.com\"\n",
    "driver.get(url)\n",
    "\n",
    "email_elem = driver.find_element_by_name(\"email\")\n",
    "email_elem.send_keys(\"„É°„Éº„É´„Ç¢„Éâ„É¨„Çπ\")\n",
    "password_elem = driver.find_element_by_name(\"pass\")\n",
    "password_elem.send_keys(\"„Éë„Çπ„ÉØ„Éº„Éâ\")\n",
    "password_elem.submit()\n",
    "time.sleep(2)\n",
    "\n",
    "# Ê§úÁ¥¢\n",
    "input_keyword = driver.find_element_by_name(\"q\")\n",
    "input_keyword.send_keys(\"codecamp\")\n",
    "input_keyword.submit()\n",
    "time.sleep(2)\n",
    "\n",
    "# CodeCamp„ÅÆÈ†ÖÁõÆ„ÇíÁ¢∫ÂÆö\n",
    "link = driver.find_element_by_link_text(\"CodeCamp\")\n",
    "link.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Ëá™Âãï„Çπ„ÇØ„É≠„Éº„É´„ÉÄ„Ç¶„É≥\n",
    "#page = driver.find_element_by_tag_name(\"html\")\n",
    "#page.send_keys(Keys.END)\n",
    "\n",
    "# Ëá™Âãï„Çπ„ÇØ„É≠„Éº„É´Áπ∞„ÇäËøî„Åó\n",
    "i = 1\n",
    "scroll = 120\n",
    "\n",
    "while i < scroll:\n",
    "    try:\n",
    "        print(\"\\n„É´„Éº„ÉóÈñãÂßãÔºö\" + str(i) + \"ÂõûÁõÆ\")\n",
    "        page = driver.find_element_by_tag_name(\"html\")\n",
    "        page.send_keys(Keys.END)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "    except:\n",
    "        print(\"error...\")\n",
    "\n",
    "    finally:\n",
    "        #element = driver.find_elements_by_class_name(\"_4-u2 _4-u8\")\n",
    "        #element = len(element)\n",
    "        html = driver.page_source\n",
    "        post = html.count(\"_4-u2 _4-u8\")\n",
    "        #print(html[0:200])\n",
    "        print(\"„É´„Éº„ÉóOK: \" + str(i) + \"ÂõûÁõÆ\")\n",
    "        print(\"ÊäïÁ®øÊï∞:\" + str(post))\n",
    "        #file = open(\"facebook-html-\" + str(i) + \".html\", \"w\")\n",
    "        #file.write(html)\n",
    "        #file.close()\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "print(\"„Äê„É´„Éº„ÉóÁµÇ‰∫Ü„Äë\" )\n",
    "print(\"Ë®ò‰∫ãÊï∞:\" + str(post))\n",
    "\n",
    "x = re.findall(r'\\brel=\"dialog\">\\w+', html)\n",
    "print(x)\n",
    "print(\"„Ç∑„Çß„Ç¢„ÅÆ„ÅÇ„Å£„ÅüÊäïÁ®øÊï∞Ôºö\" + str(len(x)))\n",
    "\n",
    "# CSVÁî®„Å´„Éá„Éº„ÇøÂä†Â∑•„ÄÄ1Ê¨°ÂÖÉÈÖçÂàó„Çí 2Ê¨°ÂÖÉÈÖçÂàó„Å´Â§âÊèõ\n",
    "import numpy as np\n",
    "item = np.array(x)\n",
    "item_count = len(x)\n",
    "x = item.reshape(item_count,1)\n",
    "print(x)\n",
    "np.savetxt(\"fb_data.csv\", x, delimiter = \",\", fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
