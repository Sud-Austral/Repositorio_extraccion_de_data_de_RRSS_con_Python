{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming de Twitter a Power BI con Azure: Event Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Christian Castro \n",
      "last updated: 2020-04-20 \n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "matplotlib 3.1.3\n",
      "Propiedad de DataIntelligence\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Christian Castro\" -u -d -p numpy,pandas,matplotlib\n",
    "%watermark -a \"Propiedad de DataIntelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "\n",
    "Streaming Twitter data to Power BI with Azure\n",
    "\n",
    "https://www.msbiblog.com/2020/02/17/streaming-twitter-data-to-power-bi-with-azure/\n",
    "\n",
    "Push data to Power BI streaming datasets without writing any code using Microsoft Flow\n",
    "\n",
    "https://powerbi.microsoft.com/es-es/blog/push-rows-to-a-power-bi-streaming-dataset-without-writing-any-code-using-microsoft-flow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una plataforma de datos moderna debería ser capaz de manejar la transmisión de datos, tanto en lotes como en tiempo real. Como sociedad, hemos llegado a esperar que las organizaciones y las personas respondan a las situaciones rápidamente. No siempre podemos esperar un día hasta que el almacén de datos haya procesado el lote nocturno para analizar los datos al día siguiente. Los datos deben abordarse justo a tiempo, y algunos datos deben manejarse más rápido que otros.\n",
    "\n",
    "Por lo tanto, podríamos construir dos soluciones: una para fines operativos que reaccione a los datos de inmediato, y otra para las operaciones estratégicas. Sin embargo, ¿no sería bueno si todo fuera consistente entre sí? ¿Realmente queremos 10 silos para 10 problemas que tienen una superposición del 75%?\n",
    "\n",
    "Entonces, ¿cómo integramos el data streaming en una plataforma de datos? Azure nos brinda una herramienta para optimizar la transmisión de datos, se llama **Event Hub**. \n",
    "\n",
    "Event Hubs representa la \"puerta de entrada\" para un canal de eventos (event pipeline), a menudo llamado un ingesta de eventos en arquitecturas de soluciones. Un ingestor de eventos es un componente o servicio que se encuentra entre los editores de eventos y los consumidores de eventos para desacoplar la producción de un flujo de eventos del consumo de esos eventos. **Event Hubs** proporciona una plataforma de transmisión unificada con búfer de retención de tiempo, que desacopla a los productores de eventos de los consumidores de eventos (https://azure.microsoft.com/en-us/services/event-hubs/).\n",
    "\n",
    "**Event Hubs** puede recibir eventos y enviar esos datos a un panel de Power BI en vivo, pero también puede enviarse a una segunda tubería hacia un almacén de datos o un lago de datos para el almacenamiento a largo plazo. El almacenamiento prolongado es interesante para diferentes preguntas. Imagina volar un avión y hay un problema con la presión del aire; te gustaría saberlo de inmediato en tu tablero de instrumentos para que puedas aterrizar el avión de manera segura, pero también es posible que desees recordar con qué frecuencia hubo problemas para poder investigar más a profundidad.\n",
    "\n",
    "Vamos a configurar una solución de streaming en Azure, transmitiendo datos de Twitter a nuestra plataforma de datos en Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo el Event Hubs\n",
    "\n",
    "#### 1 Construyendo el spacename\n",
    "\n",
    "Necesitamos crear un spacename para el **Event Hubs**.\n",
    "\n",
    "Para ello vamos a Crear un recurso y escribimos **Event Hubs**. Nos saldrá a página azure de Event Hubs. Damos click a crear.\n",
    "\n",
    "Se nos dará la oportunidad de crear un Espacio de nombres.\n",
    "\n",
    "El nombre debe ser único: tweetshaciap1\n",
    "elijamos una suscripción y \n",
    "un grupo de recursos. Puedes crear un nuevo grupo de recursos si lo quieres: nuevogrupo1\n",
    "\n",
    "Para este tutorial vamos a crear el nivel básico que cuesta alrededor de 9 euros al mes. Revisa la configuración y haz clic en crear.\n",
    "\n",
    "Se inicia la implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hayamos creado el espacio de nombres, podemos crear el **Event Hubs**.\n",
    "\n",
    "Nombre del event hubs: tweetshaciap1\n",
    "\n",
    "La cantidad de particiones requeridas depende de la cantidad de aplicaciones de consumo paralelas que consumen la secuencia de eventos. Para esta demostración la dejamos en 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber creado el centro de eventos, podemos ir al recurso y configurarlo más. En el menú de la izquierda del espacio de nombres del Event Hubs, debajo de \"entidades\", hay un enlace llamado 'Event Hubs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa que necesitamos configurar es el acceso al Event Hubs. En la hoja izquierda, haga clic en **Directivas de acceso compartido** y luego haga clic en + Agregar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegúrese de que la política de acceso tenga las opciones de administrar, enviar y escuchar marcadas. Tenga en cuenta la clave principal de conexión, la necesitará más adelante.\n",
    "\n",
    "Nombre de directiva: tweetshaciap1\n",
    "\n",
    "Clave principal\n",
    "siKbAiuJqVKEDbFeYwGyAOIF/ShR7cgL1OHghg8ENKo=\n",
    "\n",
    "Clave secundaria\n",
    "+sFjmdBQtKqtV1dR5+ysL8UKDs5p3NeBOy11D0GZERc=\n",
    "\n",
    "Cadena de conexión: clave principal\n",
    "Endpoint=sb://tweetshaciap1.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap1;SharedAccessKey=siKbAiuJqVKEDbFeYwGyAOIF/ShR7cgL1OHghg8ENKo=\n",
    "\n",
    "Cadena de conexión: clave secundaria\n",
    "Endpoint=sb://tweetshaciap1.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap1;SharedAccessKey=+sFjmdBQtKqtV1dR5+ysL8UKDs5p3NeBOy11D0GZERc=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 elementos que hay que recoger:\n",
    "\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=\"Endpoint=sb://\n",
    "<NAME OF YOUR EVENTHUB NAMESPACE>\n",
    ".servicebus.windows.net/;\n",
    "SharedAccessKeyName=\n",
    "<NAME OF YOUR SHARED ACCESS KEY>\n",
    ";SharedAccessKey=\n",
    "<SHAREDACCES KEY>=\", eventhub_name=\"\n",
    "<NAME OF YOUR EVENTHUB>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Si desea utilizar datos de Twitter, necesitará una cuenta de Twitter y una aplicación de Twitter. Vaya a https://developer.twitter.com/en/apps y cree una nueva aplicación. Vaya a la página de la aplicación y seleccione la pestaña Llaves y tokens y recuerde la Clave de API de consumidor y la Clave secreta de API de consumidor. Además, seleccione Crear en Token de acceso y Secreto de token de acceso para generar los tokens de acceso. Recuerde el token de acceso y el secreto de token de acceso.\n",
    "\n",
    "Ahora tenemos un centro de eventos que está listo para recibir eventos y una cuenta de Twitter que está configurada para permitir el envío de eventos. Pero aún necesitamos transmitir eventos de Twitter a nuestro Event Hub. Cómo hacemos esto?\n",
    "Vamos a usar Azure Databricks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Azure Databricks**\n",
    "\n",
    "Azure Databricks es una plataforma de análisis basada en Apache Spark optimizada para la plataforma de servicios en la nube Microsoft Azure. Esta plataforma le permite ejecutar portátiles Python o Scala en clústeres que se pueden escalar fácilmente. Esto hace que sea muy interesante ejecutar tareas de aprendizaje automático. Últimamente, encontrará que a más y más personas también les resulta útil crear tuberías ELT / ETL. En este ejemplo, vamos a crear un cuaderno, que puede leer datos de Twitter y enviarlos a nuestro Event Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyendo un **DataBricks**\n",
    "\n",
    "Vaya al portal de Azure, cree un nuevo recurso. Busque \"Azure Databricks\" y haga clic en Crear. Elija una suscripción, grupo de recursos, ubicación y nivel de precios. Para el precio, vaya por el estándar. \n",
    "\n",
    "Suscripción: Suscripción de Azure 1\n",
    "Grupo de recursos: nuevogrupo1\n",
    "\n",
    "Detalles de instancia\n",
    "\n",
    "Nombre del área de trabajo: tweetshaciap1\n",
    "Ubicación: (US) Este de EEUU\n",
    "Plan de tarifa: Estándar (Apache Spark, seguro con Azure AD)\n",
    "\n",
    "entrará a validar...\n",
    "cundo dé un mensaje de validación correcta haz click en crear.\n",
    "La implementación entrará en curso...\n",
    "Espere.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figura 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se crea el recurso, navegue hasta él y haga clic en **Iniciar área de trabajo**.\n",
    "\n",
    "En el espacio de trabajo, en el menú de la izquierda, haga clic en \"clústeres\". Tenemos que configurar un clúster para ejecutar nuestro notebook. \n",
    "\n",
    "Haga clic en crear clúster y asígnele un nombre. Revisa la configuración. Elijo worker type standard_D3_v2 para fines de prueba, pero es posible que desee subir de nivel para tener un rendimiento más rápido. Recuerde dejar el \"terminar después de ... minutos de inactividad\" o se le cobrará innecesariamente. Una vez que esté listo, haga clic en \"crear clúster\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para enviar datos a Event Hubs desde Twitter, necesitaremos 3 bibliotecas de Python. Vaya al clúster que acaba de crear y haga clic en **Libraries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga clic en \"instalar nuevo\", elija PyPi y complete \"azure-eventhub\" en el campo de texto del paquete y haga clic en instalar. Haga lo mismo para tweepy y azure-eventhub-checkpointstoreblob-aio.\n",
    "\n",
    "Ahora que tenemos un clúster, es hora de crear un cuaderno que enviará los datos a nuestro Event Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
