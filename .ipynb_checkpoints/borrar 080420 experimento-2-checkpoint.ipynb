{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 080420 experimento-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian Castro \n",
      "last updated: 2020-04-09 \n",
      "\n",
      "numpy 1.18.2\n",
      "pandas 1.0.1\n",
      "matplotlib 3.1.3\n",
      "Propiedad de DataIntelligence\n"
     ]
    }
   ],
   "source": [
    "#%load_ext watermark\n",
    "%watermark -a \"Christian Castro\" -u -d -p numpy,pandas,matplotlib\n",
    "%watermark -a \"Propiedad de DataIntelligence\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Declaramos nuestras Twitter API Keys:\n",
    "access_token = '1230251564616515586-2KqPsCG2mIJp3irRjENgHpCfQUxTUg'\n",
    "access_token_secret = '6PJfMtYGY7w6csiIX9m1S5jFEKNZ3hE9PVkHKeN1S14iM'\n",
    "consumer_key = 'koO4XqTuWFr5ADGcE8kjIkVoU'\n",
    "consumer_secret = '3F4sk9qU8zbKBROuLPUUj1uvE2YuhseXPe0ahMQoivg4icN5bL'\n",
    "\n",
    "def from_creator(status):\n",
    "    if hasattr(status, 'retweeted_status'):\n",
    "        return False\n",
    "    elif status.in_reply_to_status_id != None:\n",
    "        return False\n",
    "    elif status.in_reply_to_screen_name != None:\n",
    "        return False\n",
    "    elif status.in_reply_to_user_id != None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Inicializamos la variable global: \n",
    "tweet_count = 0\n",
    "\n",
    "# Ingresamos el número de tweets a ser descargados:\n",
    "n_tweets = 10    \n",
    "    \n",
    "    \n",
    "class MyStreamListener(StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        if from_creator(status):\n",
    "            \n",
    "                global tweet_count\n",
    "                global n_tweets\n",
    "                global stream\n",
    "                if tweet_count < n_tweets:\n",
    "                    \n",
    "                    # Prints out the tweet\n",
    "                    print(status)\n",
    "                    tweet_count += 1\n",
    "                    \n",
    "                    # Saves tweet into a file\n",
    "                    write_on_txt=open(\"twitter_data_colegio_medico.txt\",'a')\n",
    "                    write_on_txt.write(data)\n",
    "                    write_on_txt.close() \n",
    "                    \n",
    "                    return True\n",
    "\n",
    "        else:\n",
    "            stream.disconnect()   \n",
    "                \n",
    "    def on_error(self, status_code):\n",
    "          print(status)\n",
    "    \n",
    "# Manejamos la autenticación de Twitter y la conexión a la API de Streaming de Twitter:\n",
    "l = MyStreamListener()\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "stream = Stream(auth, l)\n",
    "\n",
    "# Integramos un flitro para que busque un usuario, en éste caso de la WHO:\n",
    "# id del usuario: yo: 1230251564616515586\n",
    "usuario = ['1230251564616515586']\n",
    "stream.filter(follow=usuario)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "tweets_data_path = \"twitter_data_colegio_medico.txt\"  \n",
    "tweets_data = []  \n",
    "tweets_file = open(tweets_data_path, \"r\")  \n",
    "for line in tweets_file:  \n",
    "    try:  \n",
    "        tweet = json.loads(line)  \n",
    "        tweets_data.append(tweet)  \n",
    "    except:  \n",
    "        continue\n",
    "        \n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['Texto del tweet'] = list(map(lambda tweet: tweet['text'], tweets_data))\n",
    "tweets['Usuario'] = list(map(lambda tweet: tweet['user']['screen_name'], tweets_data))\n",
    "tweets['Fecha'] = list(map(lambda tweet: tweet['created_at'], tweets_data))\n",
    "\n",
    "#url = f\"https://twitter.com/user/status/{tweet.id}\"\n",
    "\n",
    "#tweets['id'] = list(map(lambda tweet: tweet['id'], tweets_data))\n",
    "\n",
    "tweets['id'] = list(map(lambda tweet: tweet['id'], tweets_data))\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_tweets = tweets.iloc[::-1]\n",
    "reversed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#reversed_tweets.to_excel('reversed_tweets.csv', sheet_name='primera')\n",
    "tweets.to_csv(r'reversed_tweets.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora se debe borrar el contenido del txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
