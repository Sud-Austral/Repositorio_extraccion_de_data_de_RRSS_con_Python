{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming de Twitter a Power BI con Azure: Event Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Christian Castro \n",
      "last updated: 2020-04-20 \n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "matplotlib 3.1.3\n",
      "Propiedad de DataIntelligence\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Christian Castro\" -u -d -p numpy,pandas,matplotlib\n",
    "%watermark -a \"Propiedad de DataIntelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "\n",
    "Streaming Twitter data to Power BI with Azure\n",
    "\n",
    "https://www.msbiblog.com/2020/02/17/streaming-twitter-data-to-power-bi-with-azure/\n",
    "\n",
    "Real-time Twitter sentiment analysis in Azure Stream Analytics\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-twitter-sentiment-analysis-trends\n",
    "\n",
    "https://brazilsouth.azuredatabricks.net/?o=3320861406915733#notebook/3676314873315609/command/3676314873315610\n",
    "\n",
    "\n",
    "\n",
    "**Structured Streaming with Azure Databricks into Power BI & Cosmos DB:**\n",
    "\n",
    "https://github.com/giulianorapoz/DatabricksStreamingPowerBI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una plataforma de datos moderna debería ser capaz de manejar la transmisión de datos, tanto en lotes como en tiempo real. Como sociedad, hemos llegado a esperar que las organizaciones y las personas respondan a las situaciones rápidamente. No siempre podemos esperar un día hasta que el almacén de datos haya procesado el lote nocturno para analizar los datos al día siguiente. Los datos deben abordarse justo a tiempo, y algunos datos deben manejarse más rápido que otros.\n",
    "\n",
    "Por lo tanto, podríamos construir dos soluciones: una para fines operativos que reaccione a los datos de inmediato, y otra para las operaciones estratégicas. Sin embargo, ¿no sería bueno si todo fuera consistente entre sí? ¿Realmente queremos 10 silos para 10 problemas que tienen una superposición del 75%?\n",
    "\n",
    "Entonces, ¿cómo integramos el data streaming en una plataforma de datos? Azure nos brinda una herramienta para optimizar la transmisión de datos, se llama **Event Hub**. \n",
    "\n",
    "Event Hubs representa la \"puerta de entrada\" para un canal de eventos (event pipeline), a menudo llamado un ingesta de eventos en arquitecturas de soluciones. Un ingestor de eventos es un componente o servicio que se encuentra entre los editores de eventos y los consumidores de eventos para desacoplar la producción de un flujo de eventos del consumo de esos eventos. **Event Hubs** proporciona una plataforma de transmisión unificada con búfer de retención de tiempo, que desacopla a los productores de eventos de los consumidores de eventos (https://azure.microsoft.com/en-us/services/event-hubs/).\n",
    "\n",
    "**Event Hubs** puede recibir eventos y enviar esos datos a un panel de Power BI en vivo, pero también puede enviarse a una segunda tubería hacia un almacén de datos o un lago de datos para el almacenamiento a largo plazo. El almacenamiento prolongado es interesante para diferentes preguntas. Imagina volar un avión y hay un problema con la presión del aire; te gustaría saberlo de inmediato en tu tablero de instrumentos para que puedas aterrizar el avión de manera segura, pero también es posible que desees recordar con qué frecuencia hubo problemas para poder investigar más a profundidad.\n",
    "\n",
    "Vamos a configurar una solución de streaming en Azure, transmitiendo datos de Twitter a nuestra plataforma de datos en Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo el Event Hubs\n",
    "\n",
    "#### 1 Construyendo el spacename\n",
    "\n",
    "Necesitamos crear un spacename para el **Event Hubs**.\n",
    "\n",
    "Para ello vamos a Crear un recurso y escribimos **Event Hubs**. Nos saldrá a página azure de Event Hubs. Damos click a crear.\n",
    "\n",
    "Se nos dará la oportunidad de crear un Espacio de nombres.\n",
    "\n",
    "El nombre debe ser único: tweetshaciap2\n",
    "elijamos una suscripción y \n",
    "un grupo de recursos. Puedes crear un nuevo grupo de recursos si lo quieres: nuevogrupo1\n",
    "\n",
    "Para este tutorial vamos a crear el nivel básico que cuesta alrededor de 9 euros al mes. Revisa la configuración y haz clic en crear.\n",
    "\n",
    "Se inicia la implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hayamos creado el espacio de nombres, podemos crear el **Event Hubs**.\n",
    "\n",
    "Nombre del event hubs: tweetshaciap2\n",
    "\n",
    "La cantidad de particiones requeridas depende de la cantidad de aplicaciones de consumo paralelas que consumen la secuencia de eventos. Para esta demostración la dejamos en 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber creado el Event Hubs, podemos ir al recurso y configurarlo más. En el menú de la izquierda del espacio de nombres del Event Hubs, debajo de \"entidades\", hay un enlace llamado 'Event Hubs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa que necesitamos configurar es el acceso al Event Hubs. En la hoja izquierda, haga clic en **Directivas de acceso compartido** y luego haga clic en + Agregar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegúrese de que la política de acceso tenga las opciones de administrar, enviar y escuchar marcadas. Tenga en cuenta la clave principal de conexión, la necesitará más adelante.\n",
    "\n",
    "Nombre de directiva: tweetshaciap2\n",
    "\n",
    "Clave principal\n",
    "rda5AWSIz/7NsikPSbxxN+WjgcruKpKc6bqQJJ9zj2Y=\n",
    "\n",
    "Clave secundaria\n",
    "Lq4srrSvN/A8fnEsSYXbpBw9ZluFJNlZflVinOzjsnE=\n",
    "\n",
    "Cadena de conexión: clave principal\n",
    "Endpoint=sb://tweetshaciap2.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap2;SharedAccessKey=rda5AWSIz/7NsikPSbxxN+WjgcruKpKc6bqQJJ9zj2Y=\n",
    "\n",
    "Cadena de conexión: clave secundaria\n",
    "Endpoint=sb://tweetshaciap2.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap2;SharedAccessKey=Lq4srrSvN/A8fnEsSYXbpBw9ZluFJNlZflVinOzjsnE="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 elementos que hay que recoger:\n",
    "\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=\"Endpoint=sb://\n",
    "<NAME OF YOUR EVENTHUB NAMESPACE>\n",
    ".servicebus.windows.net/;\n",
    "SharedAccessKeyName=\n",
    "<NAME OF YOUR SHARED ACCESS KEY>\n",
    ";SharedAccessKey=\n",
    "<SHAREDACCES KEY>=\", eventhub_name=\"\n",
    "<NAME OF YOUR EVENTHUB>\")\n",
    "    \n",
    "    \n",
    "Endpoint=sb://tweetshaciap2.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap2;SharedAccessKey=rda5AWSIz/7NsikPSbxxN+WjgcruKpKc6bqQJJ9zj2Y=;EntityPath=tweetshaciap2   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Si desea utilizar datos de Twitter, necesitará una cuenta de Twitter y una aplicación de Twitter. Vaya a https://developer.twitter.com/en/apps y cree una nueva aplicación. Vaya a la página de la aplicación y seleccione la pestaña Llaves y tokens y recuerde la Clave de API de consumidor y la Clave secreta de API de consumidor. Además, seleccione Crear en Token de acceso y Secreto de token de acceso para generar los tokens de acceso. Recuerde el token de acceso y el secreto de token de acceso.\n",
    "\n",
    "Ahora tenemos un centro de eventos que está listo para recibir eventos y una cuenta de Twitter que está configurada para permitir el envío de eventos. Pero aún necesitamos transmitir eventos de Twitter a nuestro Event Hub. Cómo hacemos esto?\n",
    "Vamos a usar Azure Databricks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Azure Databricks**\n",
    "\n",
    "Azure Databricks es una plataforma de análisis basada en Apache Spark optimizada para la plataforma de servicios en la nube Microsoft Azure. Esta plataforma le permite ejecutar portátiles Python o Scala en clústeres que se pueden escalar fácilmente. Esto hace que sea muy interesante ejecutar tareas de aprendizaje automático. Últimamente, encontrará que a más y más personas también les resulta útil crear tuberías ELT / ETL. En este ejemplo, vamos a crear un cuaderno, que puede leer datos de Twitter y enviarlos a nuestro Event Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyendo un **DataBricks**\n",
    "\n",
    "Vaya al portal de Azure, cree un nuevo recurso. Busque \"Azure Databricks\" y haga clic en Crear. Elija una suscripción, grupo de recursos, ubicación y nivel de precios. Para el precio, vaya por el estándar. \n",
    "\n",
    "Suscripción: Suscripción de Azure 1\n",
    "Grupo de recursos: nuevogrupo1\n",
    "\n",
    "Detalles de instancia\n",
    "\n",
    "Nombre del área de trabajo: tweetshaciap2\n",
    "Ubicación: (US) Este de EEUU\n",
    "Plan de tarifa: Estándar (Apache Spark, seguro con Azure AD)\n",
    "\n",
    "entrará a validar...\n",
    "cundo dé un mensaje de validación correcta haz click en crear.\n",
    "La implementación entrará en curso...\n",
    "Espere.\n",
    "\n",
    "Cuando se complete la instalación haga click en:\n",
    "Ir al recurso\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figura 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz clic en **Iniciar área de trabajo**.\n",
    "\n",
    "En el espacio de trabajo, en el menú de la izquierda, haz clic en \"Clusters\". Tenemos que configurar un clúster para ejecutar nuestro notebook. \n",
    "\n",
    "Haga clic en crear clúster y asígnele un nombre: \n",
    "Cluster Name: tweetshaciap2\n",
    "\n",
    "Revisa la configuración. Elijo worker type standard_D3_v2 para tener un rendimiento más rápido. Recuerda dejar el \"terminar después de ... minutos de inactividad\" o se le cobrará innecesariamente. Una vez que esté listo, haga clic en \"crear clúster\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para enviar datos a Event Hubs desde Twitter, necesitaremos 3 bibliotecas de Python. Vé al clúster que acabas de crear y haz clic en **Libraries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga clic en \"instalar nuevo\", elija PyPi y complete \n",
    "\n",
    "\"azure-eventhub\" en el campo de texto del paquete y haga clic en instalar. Haga lo mismo para \n",
    "\n",
    "tweepy y \n",
    "\n",
    "azure-eventhub-checkpointstoreblob-aio\n",
    "\n",
    "Ahora que tenemos un clúster, es hora de crear un cuaderno que enviará los datos a nuestro Event Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamemos al notebook: tweetshaciap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecer bien la cadena de conexión es lo mas complicado:\n",
    "    \n",
    "Endpoint=sb://tweetshaciap2.servicebus.windows.net/;SharedAccessKeyName=tweetshaciap2;SharedAccessKey=rda5AWSIz/7NsikPSbxxN+WjgcruKpKc6bqQJJ9zj2Y=;EntityPath=tweetshaciap2     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PowerBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de ejecutar el cuaderno. El cuaderno enviará eventos a su Event Hub.\n",
    "\n",
    "Entonces, ¿cómo podemos transmitir los datos a Event Hubs en Power BI? Podemos usar Azure Stream Analytics para hacer esto. Esta es una plataforma de análisis en tiempo real que puede manejar la transmisión de datos desde Event Hubs y enviarla a Power BI, por ejemplo.\n",
    "\n",
    "Cree un nuevo componente de Azure, elija el trabajo de Stream Analytics. Déle un nombre al trabajo y asegúrese de mantener la nube como entorno de alojamiento. Esto implementará el trabajo en Azure. También puede implementar el trabajo en un dispositivo iot-gateway en las instalaciones, pero por ahora no lo estamos haciendo. La cantidad de unidades de transmisión se puede establecer más alto para más recursos informáticos para manejar la consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se crea el trabajo, vamos a definir las entradas, la consulta y una salida. La entrada será nuestro **Event Hub**. Para crear una entrada, en el menú de la izquierda debajo de topología de trabajo, haga clic en inputs. Cree una nueva stream input, elija Event Hub como fuente. Seleccione \"Seleccionar Event Hub de sus suscripciones\" y elija el Event Hub que creó anteriormente. \n",
    "\n",
    "En \"Nombre de la política de Event Hub\", especifique el nombre de la política de acceso compartido que creamos anteriormente. Probar y guardar la consulta.\n",
    "\n",
    "Ahora tenemos que crear una salida. Cree una nueva salida y seleccione Power BI como tipo. Ahora debe iniciar sesión en Power BI para seleccionar un espacio de trabajo donde Stream Analytics se transmitirá a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
